2023-11-15 21:46:34,955 - Namespace(dataset='sp', use_areaemb=False, use_locfeat=True, use_sinusoidal=False, use_poiprox=True, model_name='AMMASI', restore_model=False, train_again=False, D=64, K=8, d=8, sigma=0.5, sigma2=0.3, val_ratio=0.1, batch_size=250, max_epoch=100, optimizer='adam', learning_rate=0.008, patience_stop=10, patience_lr=5)
2023-11-15 21:46:39,069 - Epoch 1: {'loss': 0.18562762439250946, 'root_mean_squared_error': 0.25882792472839355, 'val_loss': 0.15970614552497864, 'val_root_mean_squared_error': 0.20914366841316223, 'lr': 0.008}
2023-11-15 21:46:40,321 - Epoch 2: {'loss': 0.1627524197101593, 'root_mean_squared_error': 0.21622677147388458, 'val_loss': 0.15700094401836395, 'val_root_mean_squared_error': 0.20727071166038513, 'lr': 0.008}
2023-11-15 21:46:41,508 - Epoch 3: {'loss': 0.16299135982990265, 'root_mean_squared_error': 0.21630439162254333, 'val_loss': 0.16312694549560547, 'val_root_mean_squared_error': 0.21304279565811157, 'lr': 0.008}
2023-11-15 21:46:42,717 - Epoch 4: {'loss': 0.16023600101470947, 'root_mean_squared_error': 0.2130047082901001, 'val_loss': 0.15757018327713013, 'val_root_mean_squared_error': 0.206961527466774, 'lr': 0.008}
2023-11-15 21:46:43,945 - Epoch 5: {'loss': 0.16014473140239716, 'root_mean_squared_error': 0.2131575345993042, 'val_loss': 0.15489839017391205, 'val_root_mean_squared_error': 0.2057703286409378, 'lr': 0.008}
2023-11-15 21:46:44,854 - Test epoch: 5 	 sp 	 (0.1551265, 171589.4, 0.1190420726495727)
2023-11-15 21:46:46,031 - Epoch 6: {'loss': 0.16021209955215454, 'root_mean_squared_error': 0.21332137286663055, 'val_loss': 0.1559263914823532, 'val_root_mean_squared_error': 0.20760972797870636, 'lr': 0.008}
2023-11-15 21:46:47,166 - Epoch 7: {'loss': 0.158283993601799, 'root_mean_squared_error': 0.21157875657081604, 'val_loss': 0.15749575197696686, 'val_root_mean_squared_error': 0.2064753621816635, 'lr': 0.008}
2023-11-15 21:46:48,289 - Epoch 8: {'loss': 0.15776516497135162, 'root_mean_squared_error': 0.21114039421081543, 'val_loss': 0.15916183590888977, 'val_root_mean_squared_error': 0.21024711430072784, 'lr': 0.008}
2023-11-15 21:46:49,501 - Epoch 9: {'loss': 0.1576230525970459, 'root_mean_squared_error': 0.210783451795578, 'val_loss': 0.1533016860485077, 'val_root_mean_squared_error': 0.20259201526641846, 'lr': 0.008}
2023-11-15 21:46:50,643 - Epoch 10: {'loss': 0.15744328498840332, 'root_mean_squared_error': 0.21038833260536194, 'val_loss': 0.15730434656143188, 'val_root_mean_squared_error': 0.2069697082042694, 'lr': 0.008}
2023-11-15 21:46:50,855 - Test epoch: 10 	 sp 	 (0.15811698, 173654.19, 0.12068013563049856)
2023-11-15 21:46:52,024 - Epoch 11: {'loss': 0.1569393277168274, 'root_mean_squared_error': 0.20990727841854095, 'val_loss': 0.15353511273860931, 'val_root_mean_squared_error': 0.20169781148433685, 'lr': 0.008}
2023-11-15 21:46:53,244 - Epoch 12: {'loss': 0.15629397332668304, 'root_mean_squared_error': 0.20934024453163147, 'val_loss': 0.15267445147037506, 'val_root_mean_squared_error': 0.20187392830848694, 'lr': 0.008}
2023-11-15 21:46:54,352 - Epoch 13: {'loss': 0.15659378468990326, 'root_mean_squared_error': 0.2096235156059265, 'val_loss': 0.1575457602739334, 'val_root_mean_squared_error': 0.20544889569282532, 'lr': 0.008}
2023-11-15 21:46:55,505 - Epoch 14: {'loss': 0.15633966028690338, 'root_mean_squared_error': 0.20930954813957214, 'val_loss': 0.15063218772411346, 'val_root_mean_squared_error': 0.20021505653858185, 'lr': 0.008}
2023-11-15 21:46:56,669 - Epoch 15: {'loss': 0.15595760941505432, 'root_mean_squared_error': 0.2089465856552124, 'val_loss': 0.1538442075252533, 'val_root_mean_squared_error': 0.20370672643184662, 'lr': 0.008}
2023-11-15 21:46:56,877 - Test epoch: 15 	 sp 	 (0.15562719, 172796.5, 0.11831081576942605)
2023-11-15 21:46:58,031 - Epoch 16: {'loss': 0.15582607686519623, 'root_mean_squared_error': 0.20903100073337555, 'val_loss': 0.1625468134880066, 'val_root_mean_squared_error': 0.20869237184524536, 'lr': 0.008}
2023-11-15 21:46:59,203 - Epoch 17: {'loss': 0.15540149807929993, 'root_mean_squared_error': 0.20837627351284027, 'val_loss': 0.15463697910308838, 'val_root_mean_squared_error': 0.2064296454191208, 'lr': 0.008}
2023-11-15 21:47:00,374 - Epoch 18: {'loss': 0.15447883307933807, 'root_mean_squared_error': 0.20733791589736938, 'val_loss': 0.1551864892244339, 'val_root_mean_squared_error': 0.2031562328338623, 'lr': 0.008}
2023-11-15 21:47:01,544 - Epoch 19: {'loss': 0.15424180030822754, 'root_mean_squared_error': 0.20715859532356262, 'val_loss': 0.15200799703598022, 'val_root_mean_squared_error': 0.20242789387702942, 'lr': 0.008}
2023-11-15 21:47:02,767 - Epoch 20: {'loss': 0.14741887152194977, 'root_mean_squared_error': 0.20068417489528656, 'val_loss': 0.14863023161888123, 'val_root_mean_squared_error': 0.1986769288778305, 'lr': 0.00080000004}
2023-11-15 21:47:02,975 - Test epoch: 20 	 sp 	 (0.1493063, 167167.47, 0.11193745324565643)
2023-11-15 21:47:04,129 - Epoch 21: {'loss': 0.1457328051328659, 'root_mean_squared_error': 0.19929082691669464, 'val_loss': 0.14864248037338257, 'val_root_mean_squared_error': 0.19870413839817047, 'lr': 0.00080000004}
2023-11-15 21:47:05,250 - Epoch 22: {'loss': 0.1446492224931717, 'root_mean_squared_error': 0.19836686551570892, 'val_loss': 0.1481914222240448, 'val_root_mean_squared_error': 0.19870500266551971, 'lr': 0.00080000004}
2023-11-15 21:47:06,477 - Epoch 23: {'loss': 0.14396271109580994, 'root_mean_squared_error': 0.19789835810661316, 'val_loss': 0.1478235423564911, 'val_root_mean_squared_error': 0.19841346144676208, 'lr': 0.00080000004}
2023-11-15 21:47:07,618 - Epoch 24: {'loss': 0.14306552708148956, 'root_mean_squared_error': 0.19708789885044098, 'val_loss': 0.14818745851516724, 'val_root_mean_squared_error': 0.19849969446659088, 'lr': 0.00080000004}
2023-11-15 21:47:08,796 - Epoch 25: {'loss': 0.14255617558956146, 'root_mean_squared_error': 0.19658847153186798, 'val_loss': 0.14819113910198212, 'val_root_mean_squared_error': 0.19881069660186768, 'lr': 0.00080000004}
2023-11-15 21:47:09,014 - Test epoch: 25 	 sp 	 (0.14882469, 167686.19, 0.11140268279466142)
2023-11-15 21:47:10,197 - Epoch 26: {'loss': 0.14181272685527802, 'root_mean_squared_error': 0.1959782838821411, 'val_loss': 0.1482042670249939, 'val_root_mean_squared_error': 0.19954073429107666, 'lr': 0.00080000004}
2023-11-15 21:47:11,324 - Epoch 27: {'loss': 0.14129599928855896, 'root_mean_squared_error': 0.19548609852790833, 'val_loss': 0.14853614568710327, 'val_root_mean_squared_error': 0.19959066808223724, 'lr': 0.00080000004}
2023-11-15 21:47:12,532 - Epoch 28: {'loss': 0.14076447486877441, 'root_mean_squared_error': 0.1950734555721283, 'val_loss': 0.1488780379295349, 'val_root_mean_squared_error': 0.20003314316272736, 'lr': 0.00080000004}
2023-11-15 21:47:13,641 - Epoch 29: {'loss': 0.1385577768087387, 'root_mean_squared_error': 0.1934143602848053, 'val_loss': 0.1481688767671585, 'val_root_mean_squared_error': 0.19908420741558075, 'lr': 8.0000005e-05}
2023-11-15 21:47:14,787 - Epoch 30: {'loss': 0.13801990449428558, 'root_mean_squared_error': 0.1929454654455185, 'val_loss': 0.14825250208377838, 'val_root_mean_squared_error': 0.19935157895088196, 'lr': 8.0000005e-05}
2023-11-15 21:47:14,997 - Test epoch: 30 	 sp 	 (0.14918794, 168345.33, 0.11228123608000193)
2023-11-15 21:47:16,163 - Epoch 31: {'loss': 0.13777805864810944, 'root_mean_squared_error': 0.1927897185087204, 'val_loss': 0.14839398860931396, 'val_root_mean_squared_error': 0.1993640959262848, 'lr': 8.0000005e-05}
2023-11-15 21:47:17,276 - Epoch 32: {'loss': 0.13760291039943695, 'root_mean_squared_error': 0.1926298439502716, 'val_loss': 0.1482778787612915, 'val_root_mean_squared_error': 0.199354350566864, 'lr': 8.0000005e-05}
2023-11-15 21:47:18,366 - Epoch 33: {'loss': 0.13746428489685059, 'root_mean_squared_error': 0.1925300508737564, 'val_loss': 0.14838050305843353, 'val_root_mean_squared_error': 0.19946207106113434, 'lr': 8.0000005e-05}
2023-11-15 21:47:19,559 - Test: 	AMMASI 	 sp 	 (0.149052, 167721.2, 0.11232851325757572)
2023-11-15 21:47:19,909 - Namespace(dataset='sp', use_areaemb=False, use_locfeat=True, use_sinusoidal=False, use_poiprox=True, model_name='AMMASI', restore_model=False, train_again=False, D=64, K=8, d=8, sigma=0.5, sigma2=0.3, val_ratio=0.1, batch_size=250, max_epoch=100, optimizer='adam', learning_rate=0.008, patience_stop=10, patience_lr=5)
sp_AMMASI_64_0.5_0.3_loc_Locfeat_poi_True result
AMMASI, sp, (0.149052, 167721.2, 0.11232851325757572)
Time elapsed (hh:mm:ss ms) 0:00:46.071554
------------------------------------------


2023-11-15 18:28:22,636 - Namespace(dataset='sp', use_areaemb=True, use_locfeat=False, use_sinusoidal=True, use_poiprox=True, model_name='AMMASI', restore_model=False, train_again=False, D=64, K=8, d=8, sigma=0.2, sigma2=0.3, val_ratio=0.1, batch_size=250, max_epoch=100, optimizer='adam', learning_rate=0.008, patience_stop=10, patience_lr=5)
2023-11-15 18:28:26,741 - Epoch 1: {'loss': 0.1892918348312378, 'root_mean_squared_error': 0.27312809228897095, 'val_loss': 0.15767847001552582, 'val_root_mean_squared_error': 0.2083185911178589, 'lr': 0.008}
2023-11-15 18:28:27,937 - Epoch 2: {'loss': 0.16191387176513672, 'root_mean_squared_error': 0.21446576714515686, 'val_loss': 0.16191630065441132, 'val_root_mean_squared_error': 0.2130085527896881, 'lr': 0.008}
2023-11-15 18:28:29,153 - Epoch 3: {'loss': 0.16056910157203674, 'root_mean_squared_error': 0.21327777206897736, 'val_loss': 0.156118705868721, 'val_root_mean_squared_error': 0.20633117854595184, 'lr': 0.008}
2023-11-15 18:28:30,326 - Epoch 4: {'loss': 0.15925830602645874, 'root_mean_squared_error': 0.21186330914497375, 'val_loss': 0.15447762608528137, 'val_root_mean_squared_error': 0.204228013753891, 'lr': 0.008}
2023-11-15 18:28:31,433 - Epoch 5: {'loss': 0.15729330480098724, 'root_mean_squared_error': 0.21004778146743774, 'val_loss': 0.16232095658779144, 'val_root_mean_squared_error': 0.21150444447994232, 'lr': 0.008}
2023-11-15 18:28:32,284 - Test epoch: 5 	 sp 	 (0.1629773, 170705.98, 0.13086648582520233)
2023-11-15 18:28:33,438 - Epoch 6: {'loss': 0.15804728865623474, 'root_mean_squared_error': 0.21058416366577148, 'val_loss': 0.15302498638629913, 'val_root_mean_squared_error': 0.20164546370506287, 'lr': 0.008}
2023-11-15 18:28:34,538 - Epoch 7: {'loss': 0.15769760310649872, 'root_mean_squared_error': 0.21003486216068268, 'val_loss': 0.16057677567005157, 'val_root_mean_squared_error': 0.20911718904972076, 'lr': 0.008}
2023-11-15 18:28:35,700 - Epoch 8: {'loss': 0.15730071067810059, 'root_mean_squared_error': 0.20967024564743042, 'val_loss': 0.15695038437843323, 'val_root_mean_squared_error': 0.205305278301239, 'lr': 0.008}
2023-11-15 18:28:36,928 - Epoch 9: {'loss': 0.15618863701820374, 'root_mean_squared_error': 0.20852205157279968, 'val_loss': 0.152138814330101, 'val_root_mean_squared_error': 0.19989046454429626, 'lr': 0.008}
2023-11-15 18:28:38,099 - Epoch 10: {'loss': 0.1549755334854126, 'root_mean_squared_error': 0.2072928547859192, 'val_loss': 0.1656450629234314, 'val_root_mean_squared_error': 0.21157562732696533, 'lr': 0.008}
2023-11-15 18:28:38,298 - Test epoch: 10 	 sp 	 (0.16712622, 177630.64, 0.1322786609014675)
2023-11-15 18:28:39,567 - Epoch 11: {'loss': 0.15549691021442413, 'root_mean_squared_error': 0.2080061435699463, 'val_loss': 0.14983540773391724, 'val_root_mean_squared_error': 0.19885005056858063, 'lr': 0.008}
2023-11-15 18:28:40,705 - Epoch 12: {'loss': 0.15446625649929047, 'root_mean_squared_error': 0.20675106346607208, 'val_loss': 0.15385331213474274, 'val_root_mean_squared_error': 0.20529796183109283, 'lr': 0.008}
2023-11-15 18:28:41,878 - Epoch 13: {'loss': 0.1553134173154831, 'root_mean_squared_error': 0.20775476098060608, 'val_loss': 0.1518498957157135, 'val_root_mean_squared_error': 0.2009282410144806, 'lr': 0.008}
2023-11-15 18:28:43,039 - Epoch 14: {'loss': 0.15437613427639008, 'root_mean_squared_error': 0.20670317113399506, 'val_loss': 0.15210182964801788, 'val_root_mean_squared_error': 0.20171687006950378, 'lr': 0.008}
2023-11-15 18:28:44,214 - Epoch 15: {'loss': 0.1533045470714569, 'root_mean_squared_error': 0.20567184686660767, 'val_loss': 0.1701006144285202, 'val_root_mean_squared_error': 0.22166235744953156, 'lr': 0.008}
2023-11-15 18:28:44,410 - Test epoch: 15 	 sp 	 (0.17079458, 178900.64, 0.13291046940104168)
2023-11-15 18:28:45,623 - Epoch 16: {'loss': 0.15403376519680023, 'root_mean_squared_error': 0.20654632151126862, 'val_loss': 0.15976649522781372, 'val_root_mean_squared_error': 0.20938070118427277, 'lr': 0.008}
2023-11-15 18:28:46,840 - Epoch 17: {'loss': 0.1450212001800537, 'root_mean_squared_error': 0.19801253080368042, 'val_loss': 0.1458592265844345, 'val_root_mean_squared_error': 0.19603000581264496, 'lr': 0.00080000004}
2023-11-15 18:28:48,079 - Epoch 18: {'loss': 0.14311856031417847, 'root_mean_squared_error': 0.1961757391691208, 'val_loss': 0.14567354321479797, 'val_root_mean_squared_error': 0.1947372853755951, 'lr': 0.00080000004}
2023-11-15 18:28:49,283 - Epoch 19: {'loss': 0.14223511517047882, 'root_mean_squared_error': 0.1953938752412796, 'val_loss': 0.14511288702487946, 'val_root_mean_squared_error': 0.19398997724056244, 'lr': 0.00080000004}
2023-11-15 18:28:50,528 - Epoch 20: {'loss': 0.14159080386161804, 'root_mean_squared_error': 0.19475796818733215, 'val_loss': 0.14486631751060486, 'val_root_mean_squared_error': 0.1943594217300415, 'lr': 0.00080000004}
2023-11-15 18:28:50,736 - Test epoch: 20 	 sp 	 (0.1454957, 163638.61, 0.10950139957264962)
2023-11-15 18:28:51,839 - Epoch 21: {'loss': 0.14117586612701416, 'root_mean_squared_error': 0.19437575340270996, 'val_loss': 0.14559657871723175, 'val_root_mean_squared_error': 0.19535134732723236, 'lr': 0.00080000004}
2023-11-15 18:28:52,992 - Epoch 22: {'loss': 0.1407650113105774, 'root_mean_squared_error': 0.19394928216934204, 'val_loss': 0.14488087594509125, 'val_root_mean_squared_error': 0.19444575905799866, 'lr': 0.00080000004}
2023-11-15 18:28:54,256 - Epoch 23: {'loss': 0.1400545835494995, 'root_mean_squared_error': 0.19352179765701294, 'val_loss': 0.144602969288826, 'val_root_mean_squared_error': 0.19393007457256317, 'lr': 0.00080000004}
2023-11-15 18:28:55,419 - Epoch 24: {'loss': 0.13983868062496185, 'root_mean_squared_error': 0.19335541129112244, 'val_loss': 0.14584514498710632, 'val_root_mean_squared_error': 0.19652941823005676, 'lr': 0.00080000004}
2023-11-15 18:28:56,627 - Epoch 25: {'loss': 0.139341801404953, 'root_mean_squared_error': 0.1929369866847992, 'val_loss': 0.14642594754695892, 'val_root_mean_squared_error': 0.1959191858768463, 'lr': 0.00080000004}
2023-11-15 18:28:56,840 - Test epoch: 25 	 sp 	 (0.14658639, 164809.66, 0.11070893375808673)
2023-11-15 18:28:58,012 - Epoch 26: {'loss': 0.13863785564899445, 'root_mean_squared_error': 0.19222034513950348, 'val_loss': 0.14570723474025726, 'val_root_mean_squared_error': 0.19575020670890808, 'lr': 0.00080000004}
2023-11-15 18:28:59,189 - Epoch 27: {'loss': 0.13837581872940063, 'root_mean_squared_error': 0.19208428263664246, 'val_loss': 0.1454201489686966, 'val_root_mean_squared_error': 0.1951836794614792, 'lr': 0.00080000004}
2023-11-15 18:29:00,372 - Epoch 28: {'loss': 0.1377498358488083, 'root_mean_squared_error': 0.19158586859703064, 'val_loss': 0.14542755484580994, 'val_root_mean_squared_error': 0.19457462430000305, 'lr': 0.00080000004}
2023-11-15 18:29:01,574 - Epoch 29: {'loss': 0.13535743951797485, 'root_mean_squared_error': 0.18932221829891205, 'val_loss': 0.14491665363311768, 'val_root_mean_squared_error': 0.19499632716178894, 'lr': 8.0000005e-05}
2023-11-15 18:29:02,691 - Epoch 30: {'loss': 0.13477811217308044, 'root_mean_squared_error': 0.18894578516483307, 'val_loss': 0.14528127014636993, 'val_root_mean_squared_error': 0.19547398388385773, 'lr': 8.0000005e-05}
2023-11-15 18:29:02,906 - Test epoch: 30 	 sp 	 (0.14547151, 164625.97, 0.10811496481326645)
2023-11-15 18:29:04,077 - Epoch 31: {'loss': 0.1344752013683319, 'root_mean_squared_error': 0.18881210684776306, 'val_loss': 0.14520032703876495, 'val_root_mean_squared_error': 0.19548408687114716, 'lr': 8.0000005e-05}
2023-11-15 18:29:05,285 - Epoch 32: {'loss': 0.13432776927947998, 'root_mean_squared_error': 0.18868792057037354, 'val_loss': 0.14521460235118866, 'val_root_mean_squared_error': 0.19559212028980255, 'lr': 8.0000005e-05}
2023-11-15 18:29:06,469 - Epoch 33: {'loss': 0.13415910303592682, 'root_mean_squared_error': 0.1886422485113144, 'val_loss': 0.14539746940135956, 'val_root_mean_squared_error': 0.19561637938022614, 'lr': 8.0000005e-05}
2023-11-15 18:29:07,682 - Test: 	AMMASI 	 sp 	 (0.1456143, 164063.95, 0.10950407924107142)
2023-11-15 18:29:08,038 - Namespace(dataset='sp', use_areaemb=True, use_locfeat=False, use_sinusoidal=True, use_poiprox=True, model_name='AMMASI', restore_model=False, train_again=False, D=64, K=8, d=8, sigma=0.2, sigma2=0.3, val_ratio=0.1, batch_size=250, max_epoch=100, optimizer='adam', learning_rate=0.008, patience_stop=10, patience_lr=5)
sp_AMMASI_64_0.2_0.3_loc_Sinusoidal_poi_True result
AMMASI, sp, (0.1456143, 164063.95, 0.10950407924107142)
Time elapsed (hh:mm:ss ms) 0:00:46.725852
------------------------------------------

